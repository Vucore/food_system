# backend/app/core/ai_predict.py
from datetime import datetime
from typing import Dict, Any, Optional, List
import os

from app.utils.food_db import FoodDatabase
from app.models.load_model_eff import FoodModelPredictorEff  # Cho EfficientNet
from app.models.load_model import FoodModelPredictorTF       # Cho EfficientNet_vinh
from app.models.load_model_30_sum import FoodModelPredictorSwin  # Cho Swin Transformer
from app.utils.vietnamese import format_food_name_with_accent

from pathlib import Path

# Th√™m v√†o ƒë·∫ßu file ai_predict.py, sau import
BASE_DIR = Path(__file__).resolve().parent.parent  # Th∆∞ m·ª•c backend/app/

MODEL_CONFIGS = [
    {
        "name": "efficientnet_vu",
        "model_type": "pytorch_eff", 
        "model_path": str(BASE_DIR / "models" / "best_model_eff.pth"),
        "food_db_path": str(BASE_DIR / "data" / "food_db_eff_vu.json"),
        "num_classes": 30
    },
    {
        "name": "efficientnet_vinh",
        "model_type": "tensorflow",  
        "model_path": str(BASE_DIR / "models" / "model_pro.h5"),  
        "food_db_path": str(BASE_DIR / "data" / "food_db_eff_vinh.json"),
        "num_classes": 20
    },

    {
        "name": "swin small",
        "model_type": "pytorch_swin",
        "model_path": str(BASE_DIR / "models" / "best_swinS_food.pth"),
        "food_db_path": str(BASE_DIR / "data" / "food_db_eff_vu.json"),
        "num_classes": 30
    }
]

CONFIDENCE_THRESHOLD = 85.0  # Ng∆∞·ª°ng confidence ƒë·ªÉ chuy·ªÉn model


class AIPredictService:
    """Service d·ª± ƒëo√°n m√≥n ƒÉn v·ªõi cascade models"""
    
    def __init__(self, save_dir: str = "./images"):
        self.save_dir = save_dir
        os.makedirs(self.save_dir, exist_ok=True)
        self.models: List[Dict[str, Any]] = []
        self._load_all_models()
    
    def _load_all_models(self):
        """Load t·∫•t c·∫£ models t·ª´ config"""
        for config in MODEL_CONFIGS:
            try:
                print(f"üîÑ Loading model: {config['name']}...")
                print(f"   üìÅ Model path: {config['model_path']}")
                print(f"   üîç File exists: {os.path.exists(config['model_path'])}")
                
                # Ch·ªçn predictor ph√π h·ª£p v·ªõi model type
                if config['model_type'] == 'pytorch_eff':
                    predictor = FoodModelPredictorEff(
                        model_path=config['model_path'],
                        num_classes=config.get('num_classes', 30)
                    )
                elif config['model_type'] == 'tensorflow':
                    print(f"   üîß ƒêang kh·ªüi t·∫°o TensorFlow predictor...")
                    predictor = FoodModelPredictorTF(
                        model_path=config['model_path'],
                        class_names=None 
                    )
                    print(f"   ‚úÖ TensorFlow predictor ƒë√£ kh·ªüi t·∫°o")
                elif config['model_type'] == 'pytorch_swin':
                    predictor = FoodModelPredictorSwin(
                        model_path=config['model_path'],
                        num_classes=config.get('num_classes', 30)
                    )
                    print(f"   ‚úÖ Swin Transformer predictor ƒë√£ kh·ªüi t·∫°o")
                else:
                    raise ValueError(f"Unknown model_type: {config['model_type']}")
                
                # Load food database
                print(f"   üìä Loading food database...")
                food_db = FoodDatabase(json_path=config['food_db_path'])
                
                self.models.append({
                    "name": config['name'],
                    "predictor": predictor,
                    "food_db": food_db,
                    "config": config
                })
                
                print(f"‚úÖ Model {config['name']} loaded successfully\n")
                
            except Exception as e:
                print(f"\n‚ùå ======== ERROR LOADING MODEL {config['name']} ========")
                print(f"Error message: {e}")
                print(f"Error type: {type(e).__name__}")
                print(f"Full traceback:")
                import traceback
                traceback.print_exc()
                print(f"========================================\n")
                
        print(f"\nüìä T·ªïng s·ªë models ƒë√£ load: {len(self.models)}")
        for idx, m in enumerate(self.models, 1):
            print(f"   {idx}. {m['name']}")
        print()
    def predict_with_cascade(
        self, 
        image_data: bytes,
        filename: str,
        user_id: str = "anonymous",
        for_esp32: bool = False 
    ) -> Dict[str, Any]:
        """
        D·ª± ƒëo√°n v·ªõi cascade models
        
        Args:
            image_data: D·ªØ li·ªáu ·∫£nh bytes
            filename: T√™n file
            user_id: ID ng∆∞·ªùi d√πng
            for_esp32: True n·∫øu response cho ESP32 (kh√¥ng d·∫•u)
            
        Returns:
            Dict k·∫øt qu·∫£ d·ª± ƒëo√°n
        """
        # 1. L∆∞u ·∫£nh tr∆∞·ªõc
        timestamp_filename = datetime.now().strftime("%Y%m%d_%H%M%S") + "_" + filename
        image_path = os.path.join(self.save_dir, timestamp_filename)
        with open(image_path, "wb") as f:
            f.write(image_data)
        print(f"üì∏ ·∫¢nh ƒë√£ l∆∞u: {image_path}")
        
        # 2. Th·ª≠ d·ª± ƒëo√°n v·ªõi t·ª´ng model
        prediction_results = []
        
        for model_info in self.models:
            try:
                model_name = model_info['name']
                predictor = model_info['predictor']
                food_db = model_info['food_db']
                
                print(f"üîç ƒêang d·ª± ƒëo√°n v·ªõi model: {model_name}")
                
                # D·ª± ƒëo√°n
                result = predictor.predict(image_path)
                predicted_class = result['predicted_class']
                confidence = result['confidence']
                
                print(f"   ‚Üí {predicted_class}: {confidence}%")
                
                # L∆∞u k·∫øt qu·∫£
                prediction_results.append({
                    "model_name": model_name,
                    "predicted_class": predicted_class,
                    "confidence": confidence
                })
                
                # N·∫øu confidence >= 80%, d√πng k·∫øt qu·∫£ n√†y
                if confidence >= CONFIDENCE_THRESHOLD:
                    print(f"‚úÖ Confidence ƒë·∫°t {confidence}% - S·ª≠ d·ª•ng model {model_name}")
                    
                    # L·∫•y th√¥ng tin nh√† h√†ng
                    food_info = food_db.get_food_by_name(predicted_class)
                    
                    if not food_info:
                        food_info = {
                            "food_name": predicted_class,
                            "restaurant_name": "Unknown",
                            "address": "Unknown",
                            "google_maps": ""
                        }
                    
                    all_restaurants = food_db.get_all_restaurants_for_food(predicted_class)
                    
                     # Format t√™n m√≥n ƒÉn
                    food_name_with_accent = format_food_name_with_accent(predicted_class)
                    food_name_no_accent = predicted_class.replace('_', ' ')
                    
                    # T√™n hi·ªÉn th·ªã: c√≥ d·∫•u cho web, kh√¥ng d·∫•u cho ESP32
                    display_name = food_name_no_accent if for_esp32 else food_name_with_accent
                    
                    return {
                        "success": True,
                        "user_id": user_id,
                        "name": display_name,  # T√™n hi·ªÉn th·ªã (c√≥/kh√¥ng d·∫•u t√πy client)
                        "name_with_accent": food_name_with_accent,  # Lu√¥n c√≥ d·∫•u
                        "name_no_accent": food_name_no_accent,  # Lu√¥n kh√¥ng d·∫•u
                        "restaurant": food_info["restaurant_name"],
                        "address": food_info["address"],
                        "google_maps": food_info["google_maps"],
                        "all_restaurants": all_restaurants,
                        "image_path": image_path,
                        "confidence": float(confidence),
                        "predicted_class": predicted_class,
                        "model_used": model_name,
                        "all_model_results": prediction_results,
                        "created_at": datetime.now().isoformat()
                    }
                else:
                    print(f"‚ö†Ô∏è Confidence {confidence}% < {CONFIDENCE_THRESHOLD}% - Th·ª≠ model ti·∫øp theo")
                    
            except Exception as e:
                print(f"‚ùå Error v·ªõi model {model_name}: {e}")
                prediction_results.append({
                    "model_name": model_name,
                    "error": str(e)
                })
        
        # 3. Kh√¥ng c√≥ model n√†o ƒë·∫°t >= 80%
        print(f"‚ùå Kh√¥ng c√≥ model n√†o ƒë·∫°t confidence >= {CONFIDENCE_THRESHOLD}%")
        
        return {
            "success": False,
            "user_id": user_id,
            "name": "Khong nhan dien duoc" if for_esp32 else "Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c",
            "name_with_accent": "Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c",
            "name_no_accent": "Khong nhan dien duoc",
            "restaurant": "N/A",
            "address": "N/A",
            "google_maps": "",
            "all_restaurants": [],
            "image_path": image_path,
            "confidence": 0.0,
            "predicted_class": "Unknown",
            "model_used": "None",
            "all_model_results": prediction_results,
            "message": f"Kh√¥ng c√≥ model n√†o ƒë·∫°t confidence >= {CONFIDENCE_THRESHOLD}%",
            "created_at": datetime.now().isoformat()
        }


# Singleton instance
_ai_service_instance: Optional[AIPredictService] = None


def get_ai_service(save_dir: str = "./images") -> AIPredictService:
    """
    L·∫•y singleton instance c·ªßa AI Service
    
    Args:
        save_dir: Th∆∞ m·ª•c l∆∞u ·∫£nh
        
    Returns:
        AIPredictService instance
    """
    global _ai_service_instance
    
    if _ai_service_instance is None:
        _ai_service_instance = AIPredictService(save_dir=save_dir)
    
    return _ai_service_instance


def predict_food_cascade(
    image_data: bytes,
    filename: str,
    user_id: str = "anonymous",
    for_esp32: bool = False
) -> Dict[str, Any]:
    """
    H√†m d·ª± ƒëo√°n v·ªõi cascade models
    
    Args:
        image_data: D·ªØ li·ªáu ·∫£nh bytes
        filename: T√™n file
        user_id: ID ng∆∞·ªùi d√πng
        for_esp32: True n·∫øu response cho ESP32 (kh√¥ng d·∫•u)
        
    Returns:
        Dict k·∫øt qu·∫£ d·ª± ƒëo√°n
    """
    service = get_ai_service()
    return service.predict_with_cascade(image_data, filename, user_id, for_esp32)